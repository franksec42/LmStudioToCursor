{
  "// LM Studio Connector Settings for VS Code/Cursor": "Copy these settings to your VS Code/Cursor settings.json",
  "// Instructions": [
    "1. Start LM Studio and load your desired model",
    "2. Start the LM Studio local server",
    "3. Run: python start_server.py",
    "4. Copy the settings below to your VS Code/Cursor settings.json",
    "5. Restart VS Code/Cursor",
    "6. The AI assistant will now use your local LM Studio model"
  ],
  
  "// For Cursor - OpenAI API Configuration": {
    "openai.apiKey": "lm-studio-key",
    "openai.apiBase": "http://localhost:8000/v1",
    "openai.model": "lm-studio-model"
  },
  
  "// Alternative configuration for different extensions": {
    "ai.apiKey": "lm-studio-key",
    "ai.apiEndpoint": "http://localhost:8000/v1/chat/completions",
    "ai.model": "lm-studio-model",
    "ai.temperature": 0.7,
    "ai.maxTokens": 2048
  },
  
  "// For GitHub Copilot Chat (if supported)": {
    "github.copilot.advanced": {
      "debug.overrideEngine": "http://localhost:8000/v1/chat/completions",
      "debug.overrideProxyUrl": "http://localhost:8000"
    }
  },
  
  "// Additional AI extension compatibility": {
    "codeGPT.apiKey": "lm-studio-key",
    "codeGPT.apiUrl": "http://localhost:8000/v1/chat/completions",
    "codeGPT.model": "lm-studio-model",
    
    "tabnine.experimentalAutoImports": true,
    "tabnine.disable": false
  },
  {
    "openai.apiKey": "lm-studio-key",
    "openai.apiBase": "http://localhost:8000/v1",
    "openai.model": "qwen/qwen3-30b-a3b-2507"
  }
}
